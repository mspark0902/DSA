# ğŸ“Œ Table of Contents
![ğŸ“‘](images/image-40.png)

1. [âš¡ Big O Notation](#bigo)
2. [ğŸ› ï¸ Steps to Solve a Problem](#steps)
3. [ğŸ“‚ Data Structures](#ds)
   - ğŸ“Œ [Arrays](#arrays)
   - ğŸ”‘ [Hashtables](#hashtables)
   - ğŸ”— [Linked Lists](#ll)
   - ğŸ“¦ [Stacks and Queues](#stacks)
   - ğŸŒ³ [Trees](#trees)
   - ğŸ” [Graphs](#graphs)
4. [âš™ï¸ Algorithms](#algorithms)
   - ğŸ” [Recursions](#recursions)
   - ğŸŒ€ [Sorting](#sorting)
     - ğŸ”µ [Bubble Sort](#bubble)
     - ğŸ”· [Selection Sort](#selection)
     - ğŸŸ  [Insertion Sort](#insertion)
     - âš¡ [Merge Sort](#merge)
     - âš”ï¸ [Quick Sort](#quick)
     - ğŸ“Š [Radix Sort](#radix)
   - ğŸ” [Searching](#searching)
     - ğŸ” [Linear Search](#linear)
     - ğŸ“ˆ [Binary Search](#binary)
     - ğŸŒ [BFS (Breadth First Search)](#bfs)
     - ğŸŒ³ [DFS (Depth First Search)](#dfs)
     - ğŸ“Š [Types of DFS Traversals](#ttt)
     - ğŸš€ [Graph Algorithms: Dijkstra, Bellman-Ford, DFS, BFS](#Dijkstra)

---

## âš¡ Big O Notation <a name="bigo"></a>

![ğŸ“Š Big O Notation](images/image.png)

### ğŸ”¢ **Rules for Calculating Big O**
- âœ… **Worst Case**
- âœ… **Remove Constants**
- âœ… **Different Terms for Inputs**
- âœ… **Drop Non-Dominant Terms**

---

### ğŸ“ˆ **O(n) - Linear Time**
âœ”ï¸ As the input size increases, the number of operations **grows proportionally**.  
âœ”ï¸ Example: Using `foreach` loops and `for` loops.

---

### âš¡ **O(1) - Constant Time**
âœ”ï¸ No matter the input size, the number of operations **remains the same**.  
âœ”ï¸ Example: `console.log(array[1])`

---

### ğŸ”„ **O(nÂ²) - Quadratic Time**
![ğŸ“Š Quadratic Time](images/image-5.png)
âœ”ï¸ **Nested loops** result in `O(n * n)`, which simplifies to **O(nÂ²)**.

---

### ğŸš€ **O(n!) - Factorial Time**
âœ”ï¸ **Nested loops for every element** (very slow!).  

---

### ğŸ” **O(log n) - Logarithmic Time**
âœ”ï¸ As `n` increases, operations grow **slowly** instead of linearly or quadratically.  
![ğŸ“‰ Logarithmic Growth](images/image-28.png)  
![ğŸ“‰ Logarithmic Comparison](images/image-29.png)

---

## ğŸ“Œ **Big O Rules**
### ğŸ“‰ **Rule 1 - Worst Case** 
âœ”ï¸ Always consider the **worst-case scenario**.  
âœ”ï¸ Example: Searching for `"nemo"` in an array.  
âœ”ï¸ If `"nemo"` is the last element, **O(n)** applies.  
![Worst Case](images/image-1.png)

---

### âœ‚ï¸ **Rule 2 - Remove Constants**
âœ”ï¸ `O(1 + n/2 + 100)` simplifies to **O(n)**.  
![Remove Constants](images/image-2.png)

---

### ğŸ”€ **Rule 3 - Different Terms for Inputs**
âœ”ï¸ `O(2n)` simplifies to **O(n)**.  
âœ”ï¸ But if inputs are different:  
   - `O(a + b)`, not `O(n)`.  
![Different Inputs](images/image-4.png)

---

### ğŸ­ **Rule 4 - Drop Non-Dominants**
âœ”ï¸ Keep only **dominant terms**.  
âœ”ï¸ Example: If `x = 500`, `xÂ²` is **dominant**, so **O(xÂ²)**.  
âœ”ï¸ Nested loops increase power (`O(nÂ²) â†’ O(nÂ³)`).  
![Drop Non-Dominants](images/image-6.png)

---

## âœ¨ **Big O Notes**
- ğŸš€ **Iterating through half a collection â†’ `O(n)`**.  
- ğŸ“Š **Iterating through two different inputs â†’ `O(n + m)`**.

---

## ğŸ§ **How to Choose the Best Code?**
![Best Code](images/image-7.png)

âœ”ï¸ **Big O depends on space & time complexity**.  
âœ”ï¸ **We can also calculate Big O for space usage**.

---

## â³ **What Affects Time Complexity?**
âœ”ï¸ Arithmetic operations `(+,-,*,/)`.  
âœ”ï¸ Comparisons `(<, >, ==)`.  
âœ”ï¸ Looping (`for`, `while`).  
âœ”ï¸ Function calls.

---

## ğŸ§  **What Affects Space Complexity?**
âœ”ï¸ Variables.  
âœ”ï¸ Data structures.  
âœ”ï¸ Function calls.  
âœ”ï¸ Allocations.

---

## ğŸ› ï¸ Steps to Solve a Problem <a name="steps"></a>
1. ğŸ“ Write down the key points of the problem.  
2. ğŸ“‹ Write down sample inputs and outputs.  
3. ğŸ› ï¸ Start with an easy approach.  
4. ğŸ¤” Analyze the problems in that approach (e.g., `O(nÂ²)`).  
5. ğŸš€ Start your best approach.  
6. ğŸ›‘ Think about error checks and fixes.  
7. ğŸ§ª Test your code with all types of inputs (`null`, `undefined`, etc.).

---

## ğŸ“‚ Data Structures <a name="ds"></a>

### ğŸ“Œ Arrays <a name="arrays"></a>
- **Static Arrays**: Fixed size.  
- **Dynamic Arrays**: No fixed size.  

#### â±ï¸ Time Constraints of Array Methods
![Array Methods](images/image-10.png)

#### ğŸ“ Notes
- ğŸ“Œ If you get string-related questions, split them into arrays.  
  ![String to Array](images/image-11.png)

---

### ğŸ”‘ Hashtables <a name="hashtables"></a>
- ğŸ“Œ Key-value pairs where keys are converted into hashes.  
- ğŸ“Œ **Example:** `Objects` in JS, `Map` in JS (inserted in sequential order).  
- ğŸ“Œ **Sets** in JS can only store keys.  

#### ğŸ”‘ HashFunction
- ğŸ“Œ Converts keys into hashes and assigns a memory address.  
  ![Hash Function](images/image-12.png)  
  ![Hash Function Example](images/image-13.png)

#### âš ï¸ Hashtable Collision
- ğŸ“Œ Two different hashes may share the same memory space.  
  ![Hashtable Collision](images/image-14.png)

#### ğŸ”„ Hashtable Vs Arrays
- ğŸ“Œ Search is `O(n)` in arrays, whereas it's `O(1)` in Hashtables.  
- ğŸ“Œ Hashtables store data in different indexes, irrespective of order. Arrays store data sequentially.  
  ![Hashtable Vs Arrays](images/image-16.png)

#### âœ”ï¸ Pros and Cons
- ğŸ“Œ **Pros:** Time optimization.  
- ğŸ“Œ **Cons:** May take more space.  
  ![Hashtable Pros and Cons](images/image-15.png)

---

### ğŸ”— Linked Lists <a name="ll"></a>
- ğŸ“Œ Lists where nodes are linked. The first node is the **head**, and the last node is the **tail**.  
  ![Linked List](images/image-17.png)  
- ğŸ“Œ Each node has pointers, except the tail.  
  ![Linked List Pointers](images/image-18.png)  
- ğŸ“Œ **Visualization:** [Linked List Visualization](https://visualgo.net/en/list)  
  ![Linked List Example](images/image-19.png)

#### ğŸ”— Pointers
- ğŸ“Œ Pointers hold the reference to a memory location.  
  ![Pointers Example](images/image-20.png)

#### ğŸ”„ Doubly Linked List
- ğŸ“Œ Holds pointers to both the next and previous nodes.  
- ğŸ“Œ **Advantage:** More efficient searching.  
  ![Doubly Linked List](images/image-21.png)

#### âœ”ï¸ Pros and Cons
![Linked List Pros and Cons](images/image-22.png)

#### ğŸ”„ Difference: Singly vs Doubly
![Singly vs Doubly](images/image-23.png)

---

### ğŸ“¦ Stacks and Queues <a name="stacks"></a>

#### ğŸ“¦ Stacks
- ğŸ“Œ **Last in, first out (LIFO).**  
  ![Stack](images/image-24.png)

#### ğŸš¶â€â™‚ï¸ Queues
- ğŸ“Œ **First in, first out (FIFO).**  
  ![Queue](images/image-25.png)

#### âš ï¸ Why Not Use Arrays for Queues?
- ğŸ“Œ Reindexing occurs when popping or pushing, which is inefficient.  

---

### ğŸŒ³ Trees <a name="trees"></a>
![Tree](images/image-26.png)

#### ğŸŒ³ Binary Tree
- ğŸ“Œ Each node can have 0, 1, or 2 nodes.  
- ğŸ“Œ **Perfect Binary Tree:** All levels are filled.  
- ğŸ“Œ **Full Binary Tree:** Nodes have 0 or 2 children.  
  ![Binary Tree](images/image-27.png)

#### ğŸ” Binary Search Tree
- ğŸ“Œ **Rules:**  
  - All right child nodes are greater than the parent.  
  - All left child nodes are smaller than the parent.  
  ![Binary Search Tree](images/image-30.png)

#### âš ï¸ Unbalanced Binary Search Tree
- ğŸ“Œ Operations become costlier.  
  ![Unbalanced BST](images/image-31.png)  
  ![Unbalanced BST Example](images/image-32.png)

#### ğŸŒ³ AVL Tree
- ğŸ“Œ Automatically balances the binary tree.  

#### ğŸŒ³ Red-Black Tree
- ğŸ“Œ Automatically balances the tree by switching elements.  

#### ğŸŒ³ Heaps
- ğŸ“Œ **Max Heap:** Every parent node is greater than its children.  
- ğŸ“Œ **Min Heap:** Every parent node is smaller than its children.  
  ![Heap](images/image-33.png)

#### ğŸŒ³ Trie
- ğŸ“Œ Predefined data structure for solving string problems.  
  ![Trie](images/image-34.png)  
  ![Trie Example](images/image-35.png)  
  **Visualization:** [Trie Visualization](https://www.cs.usfca.edu/~galles/visualization/Trie.html)

---

### ğŸ” Graphs <a name="graphs"></a>
![Graph](images/image-36.png)

#### ğŸ” Types of Graphs
![Types of Graphs](images/image-37.png)  
![Types of Graphs](images/image-38.png)  
![Types of Graphs](images/image-39.png)

#### ğŸ” Types of Weighted Graphs
- ğŸ“Œ **Positive Weighted Graph:** All edges have positive weights.  
- ğŸ“Œ **Negative Weighted Graph:** At least one edge has a negative weight.  
- ğŸ“Œ **Negative Weight Cycle:** A cycle where the sum of edge weights is negative.  

---

## âš™ï¸ Algorithms <a name="algorithms"></a>

### ğŸ” Recursions <a name="recursions"></a>
- ğŸ“Œ Calling the function inside the same function with some condition.  
  ![Recursion](images/image-41.png)

#### ğŸ§ When to Use Recursion?
![Recursion Use Cases](images/image-42.png)

---

### ğŸŒ€ Sorting <a name="sorting"></a>

#### ğŸ”µ Bubble Sort <a name="bubble"></a>
- ğŸ“Œ Compare adjacent elements and swap if they are in the wrong order.  
- ğŸ“Œ Repeat until the array is sorted.  
  ![Bubble Sort](image.png)

#### ğŸ”· Selection Sort <a name="selection"></a>
- ğŸ“Œ Find the smallest element and swap it with the first unsorted element.  
- ğŸ“Œ Repeat until the array is sorted.  
  ![Selection Sort](image-1.png)

#### ğŸŸ  Insertion Sort <a name="insertion"></a>
- ğŸ“Œ Build the sorted array one element at a time by inserting each element into its correct position.  
  ![Insertion Sort](image-2.png)

#### âš¡ Merge Sort <a name="merge"></a>
- ğŸ“Œ Divide the array into two halves, sort each half, and merge them.  
  ![Merge Sort](image-3.png)

#### âš”ï¸ Quick Sort <a name="quick"></a>
- ğŸ“Œ Choose a pivot, partition the array, and recursively sort the sub-arrays.  
  ![Quick Sort](image-4.png)

#### ğŸ“Š Radix Sort <a name="radix"></a>
- ğŸ“Œ Sort numbers by their digits, starting from the least significant digit.  
  ![Radix Sort](image-5.png)

---

### ğŸ” Searching <a name="searching"></a>

#### ğŸ” Linear Search <a name="linear"></a>
- ğŸ“Œ Loop through the items and find the target value.  
- ğŸ“Œ **Best Case:** Found immediately.  
- ğŸ“Œ **Worst Case:** Found at the last index or not present.  
  ![Linear Search](image-3.png)

#### ğŸ“ˆ Binary Search <a name="binary"></a>
- ğŸ“Œ **Divide & Conquer Algorithm**.  
- ğŸ“Œ Check the **middle element**:  
  - If the target is **higher**, remove the **left half**.  
  - If the target is **lower**, remove the **right half**.  
- ğŸ“Œ **Repeat** until the target is found.  
- âš ï¸ **Only works on sorted data**.  
  ![Binary Search](image-4.png)  
  ![Binary Search Steps](image-5.png)  
  ![Binary Search Example](image-6.png)

#### ğŸŒ BFS (Breadth First Search) <a name="bfs"></a>
- ğŸ“Œ Traverse the graph **level by level**, starting from the root.  
- ğŸ“Œ **Order of Traversal:** Left to right.  
- ğŸ“Œ **Example:**  
  - For the tree below, BFS traversal order is:  
    ```[9, 4, 34, 1, 6, 12, 45]```  
  ![Binary Search Tree](image-7.png)

#### ğŸŒ³ DFS (Depth First Search) <a name="dfs"></a>
- ğŸ“Œ Traverse the graph **depth-first**, exploring as far as possible along each branch before backtracking.  
- ğŸ“Œ **Order of Traversal:**  
  - Start from the root, go deep until a leaf node is reached.  
  - Backtrack and explore the next branch.  
- ğŸ“Œ **Example:**  
  - For the tree below, DFS traversal order is:  
    ```[9, 4, 1, 6, 34, 12, 45]```  

#### ğŸ“Š Types of DFS Traversals <a name="ttt"></a>
- ğŸ“Œ **Pre-order:**  
  - Visit the **root**, then the **left subtree**, then the **right subtree**.  
- ğŸ“Œ **In-order:**  
  - Visit the **left subtree**, then the **root**, then the **right subtree**.  
- ğŸ“Œ **Post-order:**  
  - Visit the **left subtree**, then the **right subtree**, then the **root**.  
  ![DFS Traversals](image-10.png)  
  ![DFS Traversals Example](image-11.png)

---

#### ğŸš€ Graph Algorithms: Dijkstra, Bellman-Ford, DFS, BFS <a name="Dijkstra"></a>

##### 1. Dijkstra's Algorithm  
âœ… **Use when:**  
- You need the shortest path in a graph with **non-negative weights**.  
- You want an **efficient solution** (better than Bellman-Ford) for **single-source shortest path problems**.  
- You are working with **sparse graphs** (few edges).  

âŒ **Avoid if:**  
- The graph has **negative weight edges** (Dijkstra does not handle them correctly).  
- You need to find shortest paths from **multiple sources** (use **Floyd-Warshall** instead).  

ğŸ“Œ **Example Use Cases:**  
- **GPS navigation systems**  
- **Network routing** (when all link costs are non-negative)  

---

##### 2. Bellman-Ford Algorithm  
âœ… **Use when:**  
- The graph has **negative weight edges**, and you need to find the **shortest path**.  
- You need to **detect negative weight cycles** in a graph.  

âŒ **Avoid if:**  
- The graph is **large and dense** (Bellman-Ford has a **higher time complexity** than Dijkstra).  

ğŸ“Œ **Example Use Cases:**  
- **Financial applications** (detecting arbitrage in currency exchange graphs)  
- **Routing in networking** with **potential negative weights**  

---

##### 3. DFS & BFS (When They Are Better)  
âœ… **Use DFS/BFS when:**  
- You only need to **check connectivity** or **explore a graph** (not find shortest paths).  
- The graph is **unweighted**, and you need the **shortest path** (**BFS works for unweighted graphs**).  
- You're solving problems like **topological sorting, cycle detection, or maze traversal**.  

ğŸ“Œ **Example Use Cases:**  
- **Web crawling**  
- **Finding connected components in a social network**  
- **Solving mazes**  

![Graph Algorithms](image-12.png)